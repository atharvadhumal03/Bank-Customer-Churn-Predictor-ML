# Bank Churn Prediction Machine Learning Model

## üìä Project Overview
### Introduction
This project builds a machine learning system to predict customer churn for a retail bank. The goal is to analyze customer demographic and account-related features to identify which customers are most likely to leave the bank. The solution includes data preprocessing, handling class imbalance, hyperparameter tuning, model comparison and deployment with an interactive interface.

### Objectives
- Predict customer churn accurately using machine learning models.
- Handle class imbalance effectively to avoid biased predictions.
- Build a scalable preprocessing pipeline with encoding, scaling and resampling steps.
- Compare multiple models (Logistic Regression, Random Forest, XGBoost) to select the best performing one.
- Deploy a Streamlit-based app allowing bank staff to predict churn risk for new/existing customers.

## üìà Results Summary
Threshold 0.35 (Optimized):

- Successfully catches 70% of churners (recall) vs. only 53% with default.
- Trade-off: More false alarms (precision drops from 62% to 51%).
- Overall F1 score improves marginally: 0.57 ‚Üí 0.59.
- Accuracy decreases slightly: 84% ‚Üí 81%.

Key Finding: Lowering the threshold to 0.35 identifies 17% more churners (68 additional customers), which is valuable for retention campaigns despite increased false positives. The business impact depends on whether the cost of contacting non-churners outweighs the benefit of preventing additional churn

## üåê Deployment
The application is deployed on Streamlit Cloud and can be accessed at:
- **Live App:** https://bank-customer-churn-predictor-ml-7hoamatczsrgskfmoe7rjj.streamlit.app/
- **Status:** üü¢ Active

#### How to Use:
1. Enter customer details
2. Click Predict
3. Instantly view whether the customer is likely to churn or stay.

## üñºÔ∏è Screenshots
### Web Application Interface
![App Interface](screenshots/Project_GUI.png)
*Clean and intuitive user interface for churn analysis*

### Prediction Examples
![Churn](screenshots/Churn_Prediction.png)
*Churn Prediction*

![No Churn](screenshots/NotChurn_Prediction.png)
*No Churn Prediction*

## ‚öôÔ∏è Methodology
### Data Preprocessing Pipeline
- One-hot encoding for categorical features (Geography, Gender).
- Scaling of numeric features (CreditScore, Age, Balance, Salary, etc.).
- Handled class imbalance using SMOTE inside an imbalanced-learn pipeline.
- Train-test split with stratification to preserve churn ratio.

### Model Training & Tuning
- Models used: Logistic Regression, Random Forest, XGBoost.
- Hyperparameter tuning via GridSearchCV with cross-validation.
- Model comparison using the (tuned parameters from GridSearchCV) to find optimal model.
- Evaluation metrics: Accuracy, Precision, Recall, F1, ROC-AUC.
- Final comparison showed Random Forest as best candidate.

### Deployment Architecture
- Built preprocessing Pipeline: [Encoding ‚Üí Scaling].
- Built an Imbalanced Pipeline: [SMOTE ‚Üí Preprocessing ‚Üí Model].
- Developed input utility function to transform raw input data into model-compatible format.
- Serialized final model and preprocessing steps with pickle.
- Deployed with Streamlit app for real-time churn prediction.

### üõ†Ô∏è Technologies Used
1.	Python 3.x ‚Äì Core programming language
2.	Pandas & NumPy ‚Äì Data manipulation and preprocessing
3.	Scikit-learn ‚Äì ML models, pipelines, hyperparameter tuning
4.	Imbalanced-learn ‚Äì Resampling with SMOTE
5.	XGBoost ‚Äì Gradient boosting classifier
6.	Streamlit ‚Äì Web app deployment
7.	Matplotlib & Seaborn ‚Äì Data visualization
8.	Pickle ‚Äì Model serialization
